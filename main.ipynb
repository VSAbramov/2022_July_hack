{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "import pandas as pd\n",
    "import random_forest\n",
    "\n",
    "from importlib import reload\n",
    "reload(random_forest)\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df = random_forest.prepare_data(df)\n",
    "X = df.iloc[:, :-5]\n",
    "ys = df.iloc[:, -5:].values\n",
    "# загрузка тестовых данных\n",
    "df_test = pd.read_csv('test_dataset_test.csv')\n",
    "df_test = random_forest.prepare_data(df_test)\n",
    "\n",
    "# кодирование категориальных переменных\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_attribs = random_forest.intersection(random_forest.num_cols, X.columns)\n",
    "cat_unord_attribs = random_forest.intersection(random_forest.cat_unord_cols, X.columns)\n",
    "cat_ord_attribs = random_forest.intersection(random_forest.cat_ord_cols, X.columns)\n",
    "binary_attribs = random_forest.intersection(random_forest.binar_cols, X.columns)\n",
    "\n",
    "attribs_to_normilize = random_forest.intersection(random_forest.num_cols + random_forest.time_cols, X.columns)\n",
    "\n",
    "encoder_pipeline = ColumnTransformer([\n",
    "    (\"cat_unord\", \n",
    "      OneHotEncoder(handle_unknown='ignore'), \n",
    "      cat_unord_attribs + binary_attribs),\n",
    "    (\"cat_ord\", \n",
    "      OrdinalEncoder(handle_unknown ='use_encoded_value',\n",
    "                     unknown_value=-1), \n",
    "      cat_ord_attribs),\n",
    "    (\"normalize\", \n",
    "      StandardScaler(copy = False),\n",
    "      attribs_to_normilize)],\n",
    "remainder='passthrough')\n",
    "\n",
    "X_prep = encoder_pipeline.fit_transform(X)\n",
    "\n",
    "# кодирование тестовых категориальных переменных\n",
    "X_test = encoder_pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# лес с повторной выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "hyper_params = {}\n",
    "hyper_params['n_estimators'] = list(range(100, 210, 10))\n",
    "hyper_params['min_samples_leaf'] = list(range(33, 38, 1))\n",
    "\n",
    "rand_state = 777\n",
    "\n",
    "# optimized hyper-params\n",
    "hyper_params_list = []\n",
    "hyper_params_list.append({'min_samples_leaf': [8], 'n_estimators': [500]})\n",
    "hyper_params_list.append({'min_samples_leaf': [28], 'n_estimators': [600]})\n",
    "hyper_params_list.append({'min_samples_leaf': [32], 'n_estimators': [400]})\n",
    "hyper_params_list.append({'min_samples_leaf': [36], 'n_estimators': [800]})\n",
    "hyper_params_list.append({'min_samples_leaf': [37], 'n_estimators': [150]})\n",
    "\n",
    "cat_cols_bool = []\n",
    "for i in range(X.shape[1]):\n",
    "    cat_cols_bool.append(i<X.shape[1]-6)\n",
    "cat_cols_bool[-1] = True\n",
    "# cat_cols_bool[-2] = True\n",
    "\n",
    "res = []\n",
    "for i in range(5):\n",
    "    hyper_params = hyper_params_list[i]\n",
    "    y = df.iloc[:, -(5-i)]\n",
    "    y = y.astype('int')\n",
    "    best_score = float('-inf')\n",
    "    best_params = {}\n",
    "    for g in ParameterGrid(hyper_params):\n",
    "        current_score = random_forest.resample_score(X_prep, y, g, rand_state, cat_cols_bool)\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_params = g\n",
    "    print(f'Iteration: {i+1}, Score: {round(best_score, 2)}, Params: {best_params}')\n",
    "    model = RandomForestClassifier(n_jobs = -1, \n",
    "                                   random_state = rand_state,\n",
    "                                   **best_params)\n",
    "    smt = SMOTENC(categorical_features = cat_cols_bool, \n",
    "                      random_state = rand_state)\n",
    "    X_resample, y_resample = smt.fit_resample(X_prep, y)\n",
    "    model.fit(X_resample, y_resample)\n",
    "    res.append(model.predict(X_test))\n",
    "\n",
    "SMOTENC_res = pd.DataFrame(index = df_test.index, columns = df.iloc[:,-5:].columns)\n",
    "for i in range(5):\n",
    "    y_hat = res[i]\n",
    "    SMOTENC_res.iloc[:, i] = pd.Series(res[i], index = SMOTENC_res.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# лес с весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "rand_state = 777\n",
    "\n",
    "hyper_params = {}\n",
    "\n",
    "number_of_iterations = 1\n",
    "\n",
    "# оптимизированные значения\n",
    "hyper_params_list = []\n",
    "hyper_params_list.append({'randomforestclassifier__n_jobs': [-1], \n",
    "                          'randomforestclassifier__n_estimators': [500], \n",
    "                          'randomforestclassifier__min_weight_fraction_leaf': [0.18], \n",
    "                          'randomforestclassifier__class_weight': ['balanced']})\n",
    "hyper_params_list.append({'randomforestclassifier__n_jobs': [-1], \n",
    "                          'randomforestclassifier__n_estimators': [350], \n",
    "                          'randomforestclassifier__min_weight_fraction_leaf':[0.46], \n",
    "                          'randomforestclassifier__class_weight': ['balanced']})\n",
    "hyper_params_list.append({'randomforestclassifier__n_jobs': [-1], \n",
    "                          'randomforestclassifier__n_estimators': [80], \n",
    "                          'randomforestclassifier__min_weight_fraction_leaf': [0.13], \n",
    "                          'randomforestclassifier__class_weight': ['balanced']})\n",
    "hyper_params_list.append({'randomforestclassifier__n_jobs': [-1], \n",
    "                          'randomforestclassifier__n_estimators': [150], \n",
    "                          'randomforestclassifier__min_weight_fraction_leaf': [0.05], \n",
    "                          'randomforestclassifier__class_weight': ['balanced']})\n",
    "hyper_params_list.append({'randomforestclassifier__n_jobs': [-1], \n",
    "                          'randomforestclassifier__n_estimators': [400], \n",
    "                          'randomforestclassifier__min_weight_fraction_leaf': [0.25], \n",
    "                          'randomforestclassifier__class_weight': ['balanced_subsample']})\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in range(5):\n",
    "    hyper_params = hyper_params_list[i]\n",
    "    y = df.iloc[:, -(5-i)]\n",
    "    y = y.astype('int')\n",
    "    X_train, y_train = X_prep, y\n",
    "\n",
    "    model = random_forest.chose_model(X_train, y_train, \n",
    "                            number_of_iterations, hyper_params,\n",
    "                            rand_state)\n",
    "    print(f'iteration: {i+1} Score: {round(model.best_score_, 2)}')\n",
    "\n",
    "    print(model.best_params_)\n",
    "\n",
    "    y_hat = model.predict(X_test)\n",
    "    res.append(y_hat)\n",
    "\n",
    "\n",
    "#создание результата\n",
    "weights_res = pd.DataFrame(index = df_test.index, columns = df.iloc[:,-5:].columns)\n",
    "for i in range(5):\n",
    "    y_hat = res[i]\n",
    "    weights_res.iloc[:, i] = pd.Series(res[i], index = weights_res.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# объединение выводов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(index = df_test.index, columns = df.iloc[:,-5:].columns)\n",
    "for col in final.columns:\n",
    "    final[col] = (SMOTENC_res[col] + weights_res[col] + boost_res[col])>0\n",
    "    final[col] = final[col].astype('int')\n",
    "final = final.reset_index()\n",
    "final.to_csv('solution.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a4f6baeefb09a8e9dd6162b7853bfc4abe77cd6f0626ee0111803268b311645"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
